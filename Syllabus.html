<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Syllabus | StatC131A: Statistical Methods for Data Science (Fall 2025)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { --fg:#1f2328; --muted:#6a737d; --link:#0969da; --bg:#fff; --border:#d0d7de; }
    * { box-sizing: border-box; }
    body { margin:0; font:16px/1.55 -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica,Arial,sans-serif; color:var(--fg); background:var(--bg); }
    a { color:var(--link); text-decoration:none; }
    a:hover { text-decoration:underline; }
    .topbar { position:sticky; top:0; z-index:10; backdrop-filter:saturate(180%) blur(10px); background:rgba(255,255,255,.9); border-bottom:1px solid var(--border); }
    .wrap { max-width:960px; margin:0 auto; padding:0 20px; }
    .nav { display:flex; align-items:center; gap:24px; padding:14px 0; }
    .brand { font-weight:700; }
    .navlinks { margin-left:auto; display:flex; gap:16px; }
    main.wrap { padding:28px 20px 60px; }
    h1 { font-size:28px; margin:.2em 0 .6em; }
    h2 { font-size:22px; margin:26px 0 .6rem; padding-top:8px; border-top:1px solid var(--border); }
    p { margin:.6rem 0 1rem; }
    ul { margin:.4rem 0 1rem 1.25rem; }
    li { margin:.25rem 0; }
    .small { color:var(--muted); font-size:14px; }
    .ref { font-family: ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace; font-size:90%; color:var(--muted); }
    .callout { border:1px solid var(--border); border-radius:8px; padding:12px 14px; background:#fafbfc; }
    footer { border-top:1px solid var(--border); margin-top:32px; padding:16px 0; color:var(--muted); font-size:14px; }
  </style>
</head>
<body>


  <main class="wrap">
    <h1>Syllabus</h1>
    <p class="small">UC Berkeley · Fall 2025 · Statistical Methods for Data Science</p>

    <section id="description">
      <h2>Course Description</h2>
      <p>
        Stat 131A is an upper-division course that follows Data&nbsp;8 or STAT&nbsp;20. The course will teach a broad
        range of statistical methods that are used to solve data problems, including group comparisons, standard parametric
        statistical models, multivariate data visualization, multiple linear regression and classification, classification and
        regression trees, and random forests. Students will be introduced to the widely used R statistical language and they will
        obtain hands-on experience in implementing a range of statistical methods on numerous real world datasets.
      </p>
      <p>
        Basically this course covers the fundamental concepts, practical “hammers”, and accompanying implementation skills that
        will inevitably surface in any real-world data science project and for any domain.
      </p>
    </section>

    <section id="topics">
      <h2>Topics</h2>
      <ul>
        <li>Distributional Summary of Data. <span class="ref">2.1</span></li>
        <li>Visualization (Boxplots, Histograms, etc.). <span class="ref">2.1</span></li>
        <li>Discrete and continuous distributions. Normal Distribution, Central Limit Theorem. <span class="ref">2.1, 2.3, 2.4.3</span></li>
        <li>Probability. Bayes’ theorem. Naive Bayes algorithm. <span class="ref">2.1</span></li>
        <li>Sampling distributions. Bootstrapping. <span class="ref">2.4</span></li>
        <li>Confidence intervals. Parametric hypothesis testing. <span class="ref">3</span></li>
        <li>Hypothesis testing. Type I and II errors. <span class="ref">3</span></li>
        <li>Linear regression. <span class="ref">4.1–4.3, 6</span></li>
        <li>Explanation: Feature generation. Transformations. <span class="ref">6</span></li>
        <li>Evaluation: Cross-validation. Bias-variance tradeoff. Logistic regression. Classification error metrics. <span class="ref">7, 7.5</span></li>
        <li>Non-parametric methods. Kernel density estimation (KDE). <span class="ref">2.5, 4.4–4.5</span></li>
        <li>Principal components analysis (PCA). <span class="ref">5</span></li>
        <li>Clustering. <span class="ref">5.4</span></li>
        <li>Decision trees. Random Forests. <span class="ref">8</span></li>
        <li>Causal Inference</li>
        <li>Project prep</li>
      </ul>

    </section>

    <section id="grades">
      <h2>Grades</h2>

    </section>

    <section id="honesty">
      <h2>Academic Honesty Policy</h2>
      <p>
        Homework and projects must be completed independently, with the following exceptions:
      </p>
      <ul>
        <li>You may discuss specific issues/questions you have about the homework at a high level, but you must not sit down and do the assignment jointly.</li>
        <li>Giving advice about code or coding tips is also not cheating, but you cannot directly share code with other classmates.</li>
      </ul>
      <p>
        For exams, cheating includes, but is not limited to, using electronic materials in an exam beyond that allowed, copying off another person’s exam or quiz, allowing someone to copy off of your exam or quiz, and having someone take an exam or quiz for you.
      </p>
      <p>
        Requesting, obtaining, and/or using solutions from previous years or from the internet or other sources, if such happen to be available, is considered cheating. In fairness to students who put in an honest effort, cheaters will be harshly treated.
      </p>
      <ul>
        <li>Any evidence of cheating will result in a score of zero (0) on the entire assignment or examination, and perhaps a failing grade in the class.</li>
        <li>We will always report incidences of cheating to the Office of Student Conduct, which may administer additional punishment.</li>
      </ul>
    </section>

    <footer>
      <div class="wrap">
        <p>© 2025 StatC131A · UC Berkeley Statistics</p>
      </div>
    </footer>
  </main>
</body>
</html>
